# Train Scale Match COCO or Monotonous Scale Match COCO for TinyPerson
1. you need download dataset annotation to ${YOUR_DATASET_DIR} first.
2. you need change the line in your config file, assume your annotation is _\${YOUR\_DATASET\_DIR}/tiny\_set/erase\_with\_uncertain\_dataset/annotations/corner/task/tiny\_set\_train\_sw640\_sh512\_all.json_

```yaml
    TARGET_ANNO_FILE: '${YOUR_DATASET_DIR}/tiny_set/erase_with_uncertain_dataset/annotations/corner/task/tiny_set_train_sw640_sh512_all.json'
```


3. if you use monotonicity scale match and COCO as dataset E, you may need [instances_simple_merge2014.json or instances_merge2017.json](https://pan.baidu.com/s/1T09ZNJJe56L7Zea3aD0uwA)(956c), which merge all image annotations in train set and valid set. you can download it from our merged version, or merged by yourself.

instances_simple_merge2014.json and instances_merge2017.json download link:<br/>
[Baidu Pan](https://pan.baidu.com/s/1T09ZNJJe56L7Zea3aD0uwA): 956c<br/>
[Google Driver](https://drive.google.com/open?id=1K6U_KbX6HLMddgGnDIuYmfdRD7mFyIyT): <br/>

and you need change line in config file, assume your download it to _\${YOUR\_DATASET\_DIR}/coco/annotations/instances\_simple\_merge2014.json_

```yaml
    SOURCE_ANNO_FILE: '${YOUR_DATASET_DIR}/coco/annotations/instances_simple_merge2014.json'
```

# Train Scale Match COCO or Monotonous Scale Match COCO for your dataset
1. translate annotation of your dataset as coco json format.
2. choose a config file in configs/TinyCOCO as template, and make some modify.<br/>
such as choosing [MSM-FPN](https://github.com/ucas-vg/TinyBenchmark/blob/master/tiny_benchmark/configs/TinyCOCO/FPN/e2e_faster_rcnn_R_50_FPN_1x_batch4_msm_tinyperson.yaml),
```yaml
DATASETS:
  TRAIN: ("coco_2014_train", "coco_2014_valminusminival", "coco_2014_minival")
  TEST: ("coco_2014_minival",)
DATALOADER:
  USE_MORE_DA: 4
  USE_SCALE_MATCH: True
  SCALE_MATCH:
    TYPE: 'MonotonicityScaleMatch'
    SOURCE_ANNO_FILE: '${YOUR_SOURCE_DATASET_ANN_NAME}.json'
    TARGET_ANNO_FILE: '${YOUR_TARGET_DATASET_ANN_NAME}.json'
    BINS: 100
    DEFAULT_SCALE: 0.25
    SCALE_RANGE: (0.1, 1.)
    OUT_SCALE_DEAL: 'clip'
```
you need modify DATASETS to your own source dataset, if you not use COCO as source dataset.<br/>

your may need modify 
- SCALE_MATCH.SOURCE_ANNO_FILE, annotation file path of source dataset, such as COCO in paper
- SCALE_MATCH.TARGET_ANNO_FILE, annotation file path of target dataset, such as TinyPeron in paper
- SCALE_MATCH.SCALE_RANGE, which means the range of scale image from source dataset.
- SCALE_MATCH.OUT_SCALE_DEAL, which means how to choose image scale while scale generated by scale match is out of SCALE_MATCH.SCALE_RANGE.
- SCALE_MATCH.DEFAULT_SCALE, which means scale will be applied while performing scale match failed.

or choose [SM-Adap_Retina](https://github.com/ucas-vg/TinyBenchmark/blob/master/tiny_benchmark/configs/TinyCOCO/retina/adap_retina_R_50_FPN_1x_sm_tinyperson.yaml)
```yaml
DATASETS:
  TRAIN: ("coco_2014_train", "coco_2014_valminusminival", "coco_2014_minival")
  TEST: ("coco_2014_minival",)
DATALOADER:
  USE_MORE_DA: 4
  USE_SCALE_MATCH: True
  SCALE_MATCH:
    TARGET_ANNO_FILE: '${YOUR_DATASET_DIR}/tiny_set/erase_with_uncertain_dataset/annotations/corner/task/tiny_set_train_sw640_sh512_all.json'
    BINS: 100
    DEFAULT_SCALE: 0.25
    SCALE_RANGE: (0.1, 1.)
    OUT_SCALE_DEAL: 'clip'
```
which only need SCALE_MATCH.TARGET_ANNO_FILE set to annotation of your own dataset.

3. train on your config
```
export NGPUS=2
CUDA_VISIBLE_DEVICES=0,1 python -m torch.distributed.launch --nproc_per_node=$NGPUS --master_port=9001 tools/train_test_net.py --config ${config_path}
```
